{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping USGS Gages\n",
    "_Calvin Whealton_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard libraries to import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing directory. The usgs_gages.txt is a file that has been pre-screened for having over 20 years of peak flow data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency_cd</th>\n",
       "      <th>site_no</th>\n",
       "      <th>station_nm\\n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>USGS</td>\n",
       "      <td>1010000</td>\n",
       "      <td>St. John River at Ninemile Bridge, Maine\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>USGS</td>\n",
       "      <td>1010070</td>\n",
       "      <td>Big Black River near Depot Mtn, Maine\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>USGS</td>\n",
       "      <td>1010500</td>\n",
       "      <td>St. John River at Dickey, Maine\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>USGS</td>\n",
       "      <td>1011000</td>\n",
       "      <td>Allagash River near Allagash, Maine\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>USGS</td>\n",
       "      <td>1011500</td>\n",
       "      <td>St. Francis River near Connors, New Brunswick\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  agency_cd  site_no                                     station_nm\\n\n",
       "0      USGS  1010000       St. John River at Ninemile Bridge, Maine\\n\n",
       "1      USGS  1010070          Big Black River near Depot Mtn, Maine\\n\n",
       "2      USGS  1010500                St. John River at Dickey, Maine\\n\n",
       "3      USGS  1011000            Allagash River near Allagash, Maine\\n\n",
       "4      USGS  1011500  St. Francis River near Connors, New Brunswick\\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('/Users/calvinwhealton/Documents/GitHub/tdi_capstone/peak_data')\n",
    "gage_df = pd.read_csv('usgs_gages.txt', sep=\"\\t\",comment='#')\n",
    "gage_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking all data from usgs gages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/calvinwhealton/Documents/GitHub/tdi_capstone/peak_data/gages')\n",
    "\n",
    "for i in gage_df.index:\n",
    "    gage_no = \"{:08d}\".format(gage_df['site_no'][i]) # add leading zeros, if needed\n",
    "    agency_cd = gage_df['agency_cd'][i] # USGS or other agency\n",
    "    \n",
    "    # formatting url for request\n",
    "    url = 'https://nwis.waterdata.usgs.gov/nwis/peak?site_no='+gage_no+'&agency_cd=' + agency_cd + '&format=rdb'\n",
    "    \n",
    "    # reading data from url\n",
    "    gage_data_temp = pd.read_csv(url,sep='\\t',comment='#')\n",
    "    \n",
    "    # checking if it is a bad url\n",
    "    if list(gage_data_temp.columns) != ['No sites/data found using the selection criteria specified ']:\n",
    "        # dropping row that describes length of variable\n",
    "        gage_data_temp.drop(index=0,inplace=True)\n",
    "        # name for saving\n",
    "        name = gage_no+'.csv'\n",
    "        # saving\n",
    "        gage_data_temp.to_csv(name)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looping over the dataset to calculate the frequency of floods. Will use the time period 1990-2018. The frequency model used will be the log-normal distribution without a time trend parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "662477\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/Users/calvinwhealton/Documents/GitHub/tdi_capstone/peak_data/gages')\n",
    "list_files = os.listdir()\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for i in list_files:\n",
    "    gage_data_temp = pd.read_csv(i)\n",
    "    counter += gage_data_temp.shape[0]\n",
    "    \n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.82536817788045"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "662477/13852"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## making dataframe with return periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/calvinwhealton/Documents/GitHub/tdi_capstone/peak_data/gages')\n",
    "list_files = os.listdir()\n",
    "\n",
    "yr_list = ['Gage']\n",
    "for i in range(1970,2020):\n",
    "    yr_list.append(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gage</th>\n",
       "      <th>1970</th>\n",
       "      <th>1971</th>\n",
       "      <th>1972</th>\n",
       "      <th>1973</th>\n",
       "      <th>1974</th>\n",
       "      <th>1975</th>\n",
       "      <th>1976</th>\n",
       "      <th>1977</th>\n",
       "      <th>1978</th>\n",
       "      <th>...</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Gage, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 51 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_rps = pd.DataFrame(columns=yr_list)\n",
    "ts_rps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:901: RuntimeWarning: invalid value encountered in greater\n",
      "  return (a < x) & (x < b)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:901: RuntimeWarning: invalid value encountered in less\n",
      "  return (a < x) & (x < b)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:1807: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  cond2 = (x >= _b) & cond0\n",
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py:853: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:1804: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = np.asarray((x - loc)/scale, dtype=dtyp)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# index used in counting rows of dataframe\n",
    "ind = 0\n",
    "    \n",
    "for i in range(len(list_files)):\n",
    "    # reading in file\n",
    "    gage_data_temp = pd.read_csv(list_files[ind])\n",
    "    \n",
    "    # calculating log-space mean and standard deviation for peak values\n",
    "    log_std = np.log(gage_data_temp['peak_va']).std()\n",
    "    log_mean = np.log(gage_data_temp['peak_va']).mean()\n",
    "    \n",
    "    # calculating all return periods of the events\n",
    "    rps = 1/(1-norm.cdf(np.log(gage_data_temp['peak_va']), loc=log_mean, scale=log_std))\n",
    "    yrs = gage_data_temp['peak_dt'].str.slice(start=0,stop=4)\n",
    "    \n",
    "    if len(yrs) != len(yrs.unique()): # condition with more than one flood in a calendar year\n",
    "        rps_use = []\n",
    "        yrs_use = []\n",
    "        for k in yrs.unique():\n",
    "            inds1 = (yrs == k)\n",
    "            if len(inds1) != 1:\n",
    "                yrs_use.append(k)\n",
    "                rps_use.append(max(rps[inds1]))\n",
    "            else:\n",
    "                yrs_use.append(k)\n",
    "                rps_use.append(rps[inds1])\n",
    "    else:\n",
    "        yrs_use = list(yrs)\n",
    "        rps_use = list(rps)\n",
    "    \n",
    "    # assigning an row of zero values\n",
    "    ts_rps.loc[ts_rps.shape[0]] = 0\n",
    "    # getting the gage number\n",
    "    gage_temp = list_files[i].split('.')[0]\n",
    "    # assigning gage number\n",
    "    ts_rps.loc[ind]['Gage'] = gage_temp\n",
    "    \n",
    "    # putting calculated return periods in the results\n",
    "    for j in range(len(yrs_use)):\n",
    "        if yrs_use[j] in ts_rps.columns:\n",
    "            ts_rps.loc[ind][yrs_use[j]] = rps_use[j]\n",
    "    \n",
    "    # incrementing index\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13706, 51)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_rps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_rps.to_csv('ts_rps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining spatial location of each gage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
