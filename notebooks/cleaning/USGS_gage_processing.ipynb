{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping USGS Gages\n",
    "_Calvin Whealton_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to process the USGS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import datetime\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing directory. The usgs_gages.txt is a file that has been pre-screened for having over 20 years of peak flow data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/calvinwhealton/Documents/GitHub/floods_housing_zipcode/data/gage_data')\n",
    "gage_df = pd.read_csv('usgs_gages.txt', sep=\"\\t\",comment='#')\n",
    "gage_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking all data from usgs gages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/calvinwhealton/Documents/GitHub/floods_housing_zipcode/data/gage_data/peak_flows')\n",
    "\n",
    "# looping over all gages\n",
    "for i in gage_df.index:\n",
    "    gage_no = \"{:08d}\".format(gage_df['site_no'][i]) # add leading zeros, if needed\n",
    "    agency_cd = gage_df['agency_cd'][i] # USGS or other agency\n",
    "    \n",
    "    # formatting url for request\n",
    "    url = 'https://nwis.waterdata.usgs.gov/nwis/peak?site_no='+gage_no+'&agency_cd=' + agency_cd + '&format=rdb'\n",
    "    \n",
    "    # reading data from url\n",
    "    gage_data_temp = pd.read_csv(url,sep='\\t',comment='#')\n",
    "    \n",
    "    # checking if it is a bad url\n",
    "    if list(gage_data_temp.columns) != ['No sites/data found using the selection criteria specified ']:\n",
    "        # dropping row that describes length of variable\n",
    "        gage_data_temp.drop(index=0,inplace=True)\n",
    "        # name for saving\n",
    "        name = gage_no+'.csv'\n",
    "        # saving\n",
    "        gage_data_temp.to_csv(name)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looping over the dataset to calculate the frequency of floods. Will use the time period 1990-2018. The frequency model used will be the log-normal distribution without a time trend parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/calvinwhealton/Documents/GitHub/floods_housing_zipcode/data/gage_data/peak_flows')\n",
    "list_files = os.listdir()\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for i in list_files:\n",
    "    gage_data_temp = pd.read_csv(i)\n",
    "    counter += gage_data_temp.shape[0]\n",
    "    \n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating average number of years per gage\n",
    "662477/13852"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## making dataframe with return periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only returning files that are \"real\" gages\n",
    "# nothing that begins with .\n",
    "os.chdir('/Users/calvinwhealton/Documents/GitHub/floods_housing_zipcode/data/gage_data/peak_flows')\n",
    "\n",
    "def listdir_nohidden(path):\n",
    "    return glob.glob(os.path.join(path, '*'))\n",
    "\n",
    "list_files = listdir_nohidden('/Users/calvinwhealton/Documents/GitHub/floods_housing_zipcode/data/gage_data/peak_flows')\n",
    "\n",
    "yr_list = ['Gage']\n",
    "for i in range(1970,2020):\n",
    "    yr_list.append(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_rps = pd.DataFrame(columns=yr_list)\n",
    "ts_rps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index used in counting rows of dataframe\n",
    "ind = 0\n",
    "    \n",
    "for i in range(len(list_files)):\n",
    "    # reading in file\n",
    "    gage_data_temp = pd.read_csv(list_files[i])\n",
    "    gage_data_temp = gage_data_temp.loc[pd.notnull(gage_data_temp['peak_va'])]\n",
    "    \n",
    "    if gage_data_temp.shape[0] != 0:\n",
    "        # calculating log-space mean and standard deviation for peak values\n",
    "        peaks = np.array(gage_data_temp['peak_va'].values)\n",
    "        if min(peaks) == 0:\n",
    "            peaks[peaks == 0] = 0.99*min(peaks[peaks > 0])\n",
    "\n",
    "        log_std = np.log(peaks).std()\n",
    "        log_mean = np.log(peaks).mean()\n",
    "\n",
    "        # calculating all return periods of the events\n",
    "        rps = 1/(1-norm.cdf(np.log(gage_data_temp['peak_va']), loc=log_mean, scale=log_std))\n",
    "        yrs = gage_data_temp['peak_dt'].str.slice(start=0,stop=4)\n",
    "\n",
    "        if len(yrs) != len(yrs.unique()): # condition with more than one flood in a calendar year\n",
    "            rps_use = []\n",
    "            yrs_use = []\n",
    "            for k in yrs.unique():\n",
    "                inds1 = (yrs == k)\n",
    "                if len(inds1) != 1:\n",
    "                    yrs_use.append(k)\n",
    "                    rps_use.append(max(rps[inds1]))\n",
    "                else:\n",
    "                    yrs_use.append(k)\n",
    "                    rps_use.append(rps[inds1])\n",
    "        else:\n",
    "            yrs_use = list(yrs)\n",
    "            rps_use = list(rps)\n",
    "\n",
    "        # assigning an row of zero values\n",
    "        ts_rps.loc[ts_rps.shape[0]] = 0\n",
    "        # getting the gage number\n",
    "        gage_temp = list_files[i].split(\"/\").pop().split(\".\")[0]\n",
    "        # assigning gage number\n",
    "        ts_rps.loc[ind]['Gage'] = gage_temp\n",
    "\n",
    "        # putting calculated return periods in the results\n",
    "        for j in range(len(yrs_use)):\n",
    "            if yrs_use[j] in ts_rps.columns:\n",
    "                ts_rps.loc[ind][yrs_use[j]] = rps_use[j]\n",
    "    \n",
    "        # incrementing index\n",
    "        ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_rps.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_rps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/calvinwhealton/Documents/GitHub/floods_housing_zipcode/data/processed_data')\n",
    "ts_rps.to_csv('ts_rps_2020-08-15.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
