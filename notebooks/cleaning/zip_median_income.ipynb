{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zip Code Median Income\n",
    "_Calvin Whealton_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook combines the data from the US Census American Community Survey 2018. The data were downloaded from the US Census website, specifically tables S1901 for each of the 48 contiguous states and Washington, DC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the data is available at the county subdivision, but not the zip code, the values must be spatially disaggregated and summed. This is accomplished by using a file that maps between the zip code and the county subdivision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stitching State Data Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section merges the files together to make one file that is the median income. There are many more data fields that are not processed. The column for median income estimate for the county subdivision is S1901_C01_012E."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/calvinwhealton/Documents/GitHub/floods_housing_zipcode/data/us_census_s1901_income/csvs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_incs_list = os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe for values of median income in each county subdivision\n",
    "state_medinc_cousub = pd.DataFrame(columns=['GEOID_COUSUB','med_hh_inc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all files (states)\n",
    "for file in state_incs_list:\n",
    "    \n",
    "    # row 1 has explanation/long captions for column titles\n",
    "    state_inc = pd.read_csv(file,skiprows=[1])\n",
    "    \n",
    "    # dictionary of values from the state\n",
    "    state_med = pd.DataFrame({'GEOID_COUSUB':state_inc['GEO_ID'],\n",
    "                              'med_hh_inc':state_inc['S1901_C01_012E']})\n",
    "    \n",
    "    # appending values to the large state dataframe\n",
    "    state_medinc_cousub = state_medinc_cousub.append(state_med,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing some basic checks and post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_medinc_cousub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_medinc_cousub.isnull().sum(axis=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_medinc_cousub = state_medinc_cousub.dropna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_medinc_cousub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_medinc_cousub['GEOID_CS'] = [string.split('US')[1] for string in state_medinc_cousub['GEOID_COUSUB']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_medinc_cousub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/calvinwhealton/Documents/GitHub/floods_housing_zipcode/data/processed_data')\n",
    "state_medinc_cousub.to_csv('state_medinc_cousub.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregating/Disaggregating to Zip Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median household income for a zip code will be assigned as the median income based on a population-weighted median income for the zip codes that share the value. For example, if zip code 12345 is composed of 40% of the population from county subdivision 23 with median income 10,000 and 60%  from county subdivision 45 with median income 20,000, then the estimated median income for the zip code will be 10,000x0.4 + 20,000x0.6 = 4,000 + 12,000 = 16,000. In the case where some county subdivisions do not have data, the fractions are normalized to sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/calvinwhealton/Documents/GitHub/floods_housing_zipcode/data')\n",
    "\n",
    "zcta_cousub_map = pd.read_csv('zcta_countysub_uscensus.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcta_cousub_map.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_med_inc = pd.DataFrame(columns=['zip','med_hh_inc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique values of zip code\n",
    "zip_use = zcta_cousub_map.ZCTA5.unique()\n",
    "\n",
    "\n",
    "# loop over every zip code\n",
    "for zc in zip_use:\n",
    "    \n",
    "    # used in calculations for each zip code\n",
    "    temp_df = pd.DataFrame()\n",
    "    \n",
    "    # geoids for the county\n",
    "    # casting to string to match string in other dataframe\n",
    "    cou_geoids = zcta_cousub_map.loc[zcta_cousub_map['ZCTA5'] == zc,'GEOID'].astype(str).values\n",
    "    cou_df = zcta_cousub_map.loc[zcta_cousub_map['ZCTA5'] == zc]\n",
    "    \n",
    "    # searching for geoids in the median income data\n",
    "    temp_df = state_medinc_cousub.loc[state_medinc_cousub['GEOID_CS'].isin(cou_geoids)]\n",
    "    \n",
    "    if temp_df.shape[0] == 0:\n",
    "        zip_med_inc = zip_med_inc.append({'zip':zc, 'med_hh_inc': np.NaN},ignore_index=True)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # adding column for population fraction [0,100]\n",
    "        temp_df['pop_frac'] = 0\n",
    "        \n",
    "        #finding the fractions that match the county subdivisions\n",
    "        for i in temp_df.index:\n",
    "            temp_df.loc[i,'pop_frac'] = cou_df.loc[cou_df['GEOID'].values.astype(str) == temp_df.loc[i,'GEOID_CS'],'ZPOPPCT'].values\n",
    "        \n",
    "        # empty values removed\n",
    "        temp_df = temp_df[temp_df['med_hh_inc'] != '-']\n",
    "        \n",
    "        # special cases for the boundary values of income\n",
    "        # only listed as above or below a value\n",
    "        for i in temp_df.index:\n",
    "            if temp_df.loc[i,'med_hh_inc'] == '250,000+':\n",
    "                temp_df.loc[i,'med_hh_inc'] = '250000'\n",
    "            if temp_df.loc[i,'med_hh_inc'] == '2,500-':\n",
    "                temp_df.loc[i,'med_hh_inc'] = '2500'\n",
    "        \n",
    "        # estimate of the median income\n",
    "        est_med_inc = np.sum(np.array(temp_df['pop_frac'].values)*np.array(temp_df['med_hh_inc'].values.astype(float)))/(np.sum(np.array(temp_df['pop_frac'].values)))\n",
    "        \n",
    "        zip_med_inc = zip_med_inc.append({'zip':zc, 'med_hh_inc': est_med_inc},ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic checks and cleaning following operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_med_inc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_med_inc.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_med_inc.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_med_inc = zip_med_inc.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/calvinwhealton/Documents/GitHub/floods_housing_zipcode/data/processed_data')\n",
    "zip_med_inc.to_csv('zips_med_inc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
