{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trends in Flood Gages\n",
    "_Calvin Whealton_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook calculates the trends in the stream gages. Each stream gage is assessed and the Kendal Tau is calculated between the peak flows and \"year\" of the flood. Gages with trends are identified and the significance of the trend measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import kendalltau\n",
    "from scipy.stats import linregress\n",
    "from scipy.stats import norm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chaning working directory to where the peak flow data is located\n",
    "os.chdir('/Users/calvinwhealton/Documents/GitHub/floods_housing_zipcode/data/gage_data/peak_flows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of files in directory\n",
    "list_files = os.listdir()\n",
    "\n",
    "# dataframe that will store results\n",
    "kendallt_df = pd.DataFrame(columns=['gage','tau','pvalue','slope_rel_ref'])\n",
    "\n",
    "for f in list_files:\n",
    "    # read in file\n",
    "    # all files in directory have the same structure\n",
    "    # all were scraped from the USGS\n",
    "    temp = pd.read_csv(f)\n",
    "    \n",
    "    if len(temp) != 0:\n",
    "\n",
    "        # peak values\n",
    "        peaks = np.array(temp['peak_va'].values)\n",
    "        keepers = (np.isnan(peaks) == False)\n",
    "        peaks = peaks[keepers]\n",
    "        \n",
    "        # years\n",
    "        temp['yr'] = [int(x.split('-')[0]) for x in temp['peak_dt'].values]\n",
    "        yrs = np.array(temp['yr'].values)[keepers]\n",
    "        \n",
    "        if len(peaks) > 15:\n",
    "\n",
    "            # calculated kendall tau\n",
    "            kendall_tau_lag1 = kendalltau(peaks,yrs)\n",
    "\n",
    "            # calculating overall trend in floods\n",
    "            # ordinary linear regression\n",
    "            slope, intercept, r_value, p_value, std_err = linregress(yrs,peaks)\n",
    "            #print(slope)\n",
    "            #print(intercept)\n",
    "\n",
    "            # dealing with special case of a zero peak flow\n",
    "            # setting it to 90% of the smallest \"observed\" flow\n",
    "            # setting smaller would make the standard deviation blow up\n",
    "            if min(peaks) == 0:\n",
    "                peaks[peaks == 0] = 0.99*min(peaks[peaks > 0])\n",
    "            \n",
    "            # log-space mean and standard deviation\n",
    "            mean_ls = np.mean(np.log(peaks))\n",
    "            sd_ls = np.std(np.log(peaks))\n",
    "            \n",
    "            # measure of increase\n",
    "            # calcualte the slope as a fraction of the nominal 100-year flood\n",
    "            fl_ref = np.exp(norm.ppf(0.5, loc=mean_ls, scale=sd_ls))\n",
    "            slope_rel_fl_ref = slope/np.mean(peaks)\n",
    "\n",
    "            # adding to dataframe\n",
    "            kendallt_df = kendallt_df.append({'gage': f.split('.')[0],\n",
    "                                              'tau': kendall_tau_lag1.correlation,\n",
    "                                              'pvalue': kendall_tau_lag1.pvalue,\n",
    "                                              'slope_rel_ref':slope_rel_fl_ref},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3117550905249261"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(kendallt_df['slope_rel_ref'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2449"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array(kendallt_df['slope_rel_ref'].values) > 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "kendallt_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/calvinwhealton/Documents/GitHub/floods_housing_zipcode/data/processed_data')\n",
    "kendallt_df.to_csv('gage_trends.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
