{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Figures for Zip Codes\n",
    "_Calvin Whealton_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook develops creates visualizations for each zip code about the expected results on the housing market following a 100-year flood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis for Typical GDP and Housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding some ranges of typical GDP and housing prices that will be used. The number of lines per zip code is the product of these two results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# housing data\n",
    "os.chdir('/Users/calvinwhealton/Documents/GitHub/floods_housing_zipcode/data/processed_data')\n",
    "housing = pd.read_csv('zillow_mon_pct_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.quantile(q=[0.1,0.25,0.5,0.75,0.9], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above results, a \"bad\" market would be in the range of -0.2 to -0.5 % month-over-month. A \"good market would be about 0.75 to 0.85 % month-over-month. Typical values might be in the range of 0.2 to 0.3 % month-over-month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For typical values for each zip code, constant values of -0.4, 0.0, 0.3, and 0.8 will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdp data\n",
    "os.chdir('/Users/calvinwhealton/Documents/GitHub/floods_housing_zipcode/data')\n",
    "gdp = pd.read_csv('A191RL1Q225SBEA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating some quantiles of the quarterly gdp\n",
    "gdp.iloc[(293-4*25):293].quantile(q=[0.1,0.25,0.5,0.75,0.9], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above results, the \"bad\" value of quarterly GDP change would be -0.6, a typical value would be 2, and a good value would be 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating all combinations of the above results (4 housing prices and 3 gdps) would give 12 lines total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Files with Demographic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in the files for zip codes that will include the population density and median income for the zip code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shapefile for zip code\n",
    "#shapefile available from https://drive.google.com/file/d/1yTwgTfbYZirtNQOIfgQVDY4Tc-QKDVTb/view?usp=sharing\n",
    "os.chdir('/Users/calvinwhealton/Documents/GitHub/floods_housing_zipcode/data/geo_data/tl_2019_us_zcta510_clipped48contig')\n",
    "zips_shapefile = gpd.read_file('clipped48contig.shp')\n",
    "\n",
    "# mapping between zip code and county subdivision\n",
    "os.chdir('/Users/calvinwhealton/Documents/GitHub/floods_housing_zipcode/data')\n",
    "zcta_cousub = pd.read_csv('zcta_countysub_uscensus.txt')\n",
    "\n",
    "# creating dataframe for zip code and area\n",
    "zips_key_vals = pd.DataFrame({'zips':zips_shapefile['GEOID10'].astype(int).values,\n",
    "                              'area':zips_shapefile['ALAND10'].values })\n",
    "\n",
    "\n",
    "# creating dataframe for zip code and population\n",
    "pop_df = pd.DataFrame({'zips':(zcta_cousub.groupby('ZCTA5').mean())['ZPOP'].index,\n",
    "                      'zpop':(zcta_cousub.groupby('ZCTA5').mean())['ZPOP']})\n",
    "\n",
    "# merging dataframes and calculating the population density\n",
    "zips_key_vals2 = pd.merge(left=zips_key_vals, right = pop_df, left_on = 'zips', right_on = 'zips')\n",
    "zips_key_vals2['pop_dens'] = zips_key_vals2['zpop']/zips_key_vals2['area']\n",
    "\n",
    "# loading dataframe with median income\n",
    "os.chdir('/Users/calvinwhealton/Documents/GitHub/floods_housing_zipcode/data/processed_data')\n",
    "zip_medinc = pd.read_csv('zips_med_inc.csv')\n",
    "\n",
    "# merging to have demographic characteristics in one dataframe\n",
    "zips_key_vals3 = pd.merge(left=zips_key_vals2, right = zip_medinc, left_on = 'zips', right_on = 'zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Pickled Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the user-defined transformers and estimators before the pickled file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import base\n",
    "class ColumnSelectTransformer(base.BaseEstimator, base.TransformerMixin):\n",
    "    '''\n",
    "    Transformer used in the practical machine learning mini project\n",
    "    Selects the columns defined as col_names from the dataframe\n",
    "    Returns the values for those columns\n",
    "    Does not need to learn anything about the data\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, col_names):\n",
    "        self.col_names = col_names\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        rets = np.zeros((X.shape[0], len(self.col_names)))\n",
    "        for c in range(len(self.col_names)):\n",
    "            rets[:,c] = X[self.col_names[c]]\n",
    "        return rets\n",
    "    \n",
    "    \n",
    "class LogTransformer(base.BaseEstimator, base.TransformerMixin):\n",
    "    '''\n",
    "    Transforms columns as the logarithm of the given values\n",
    "    It does not have to learn anything about the data\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.log(X)\n",
    "    \n",
    "class TimeSeriesRescaler(base.BaseEstimator, base.TransformerMixin):\n",
    "    '''\n",
    "    Transforms columns as a time series\n",
    "    Scales around a mean value of 0\n",
    "    Uses standard deviation of the whole series\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.std = np.std(X)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return [row/self.std for row in X]\n",
    "    \n",
    "class MoveRefScale(base.BaseEstimator, base.TransformerMixin):\n",
    "    '''\n",
    "    Transforms columns as the logarithm of the given values\n",
    "    It does not have to learn anything about the data\n",
    "    Assumes X is a single input\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,ref=None,scaler='std'):\n",
    "        self.scaler = scaler\n",
    "        self.ref = ref\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        if self.ref is None:\n",
    "            self.ref_use = np.mean(X)\n",
    "        else:\n",
    "            self.ref_use = self.ref\n",
    "        \n",
    "        if self.scaler == 'std':\n",
    "            self.scale_value = np.std(X)\n",
    "        if self.scaler == 'min_max':\n",
    "            self.scale_value = np.max(X) - np.min(X)\n",
    "        if self.scaler == 'iqr':\n",
    "            self.scale_value = np.quantile(X,0.75) - np.quantile(X,0.25)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return (X-self.ref_use)/self.scale_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe_rp = Pipeline([\n",
    "                ('cst_rp', ColumnSelectTransformer(col_names=['flood_rp'])),\n",
    "                ('lt_rp', LogTransformer()),\n",
    "                ('mrs_rp',  MoveRefScale(ref=np.log(100), scaler='iqr'))\n",
    "])\n",
    "\n",
    "\n",
    "pipe_gdp = Pipeline([\n",
    "                ('cst_gdp', ColumnSelectTransformer(col_names=['GDP'])),\n",
    "                ('mrs_gdp', MoveRefScale(ref=0.0, scaler='std'))\n",
    "])\n",
    "\n",
    "pipe_inc = Pipeline([\n",
    "                ('cst_inc', ColumnSelectTransformer(col_names=['med_inc'])),\n",
    "                ('lt_inc', LogTransformer()),\n",
    "                ('mrs_inc', MoveRefScale(ref=None,scaler='std'))\n",
    "])\n",
    "\n",
    "pipe_popden = Pipeline([\n",
    "                ('cst_pden',  ColumnSelectTransformer(col_names=['pop_dens'])),\n",
    "                ('lt_pden', LogTransformer()),\n",
    "                ('mrs_pden', MoveRefScale(ref=None,scaler='std'))\n",
    "])\n",
    "\n",
    "pipe_houTS = Pipeline([\n",
    "                ('cst_gdp', ColumnSelectTransformer(col_names=['h-12', 'h-11','h-10','h-09', 'h-08','h-07','h-06','h-05','h-04','h-03','h-02','h-01'])),\n",
    "                ('tsr_gdp', TimeSeriesRescaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union = FeatureUnion([\n",
    "        ('rp',pipe_rp),\n",
    "        ('gdp',pipe_gdp),\n",
    "        ('inc',pipe_inc),\n",
    "        ('popden',pipe_popden),\n",
    "        ('houTS', pipe_houTS)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNMixedTSConsts(base.BaseEstimator, base.RegressorMixin):\n",
    "    '''\n",
    "    Custom estimator for the time series data (and non-time series) for problem\n",
    "    neighbors = number of neighbors\n",
    "    ts_inds = indices of the time series (assumed to be in correct order)\n",
    "    weights = weights for different parts of distance (time series collapsed to singe distance then weighted)\n",
    "    '''\n",
    "\n",
    "    def __init__(self,neighbors,ts_inds, weights):\n",
    "        self.neighbors = neighbors\n",
    "        self.ts_inds = ts_inds\n",
    "        self.weights = weights\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X = X # store the values passed in\n",
    "        self.y = y\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # prediction will be the mean of the k nearest neighbors\n",
    "        # prediction also will return 80% interval\n",
    "        # size will be number_of_prediction * length_of_time_series * number_of_metrics\n",
    "        num_metrics = 3\n",
    "        num_preds = X.shape[0]\n",
    "        length_of_ts = self.y.shape[1]\n",
    "        \n",
    "        pred_arr = np.zeros((num_preds, length_of_ts, num_metrics))\n",
    "        \n",
    "        ts_vals = np.array(self.y)\n",
    "        \n",
    "        for p in range(num_preds):\n",
    "            \n",
    "            # calculate the distance\n",
    "            dists = dist_calc(X[p,:], self.X, self.ts_inds, self.weights)\n",
    "            \n",
    "            # find neighbors by index\n",
    "            neighbors_close = (np.argsort(dists))[0:self.neighbors]\n",
    "            \n",
    "            # take mean down the columns\n",
    "            # length will be same as number of columns\n",
    "            # also estimate the quantiles\n",
    "            pred_arr[p,:,0] = np.mean(ts_vals[neighbors_close],axis=0)\n",
    "            \n",
    "            pred_arr[p,:,1] = np.quantile(ts_vals[neighbors_close], 0.1,axis=0)\n",
    "            pred_arr[p,:,2] = np.quantile(ts_vals[neighbors_close], 0.9,axis=0)\n",
    "        \n",
    "        return pred_arr\n",
    "    \n",
    "    \n",
    "def dist_calc(X_fitting, X_mat, ts_inds, weights):\n",
    "    \n",
    "    # dimensions and initializing an array to store results\n",
    "    nrows = np.array(X_mat).shape[0]\n",
    "    ncols = np.array(X_mat).shape[1] - len(ts_inds) + 1\n",
    "    dist = np.zeros((nrows, ncols))\n",
    "    \n",
    "    # calculate the distances\n",
    "    for i in np.arange(ncols):\n",
    "        if i != (ncols - 1):\n",
    "            dist[:,i] = weights[i]*((np.array(X_mat[:,i])-X_fitting[i])**2)\n",
    "        else:\n",
    "            dist_ts = np.zeros((nrows,len(ts_inds)))\n",
    "            for j in range(len(ts_inds)):\n",
    "                dist_ts[:,j] = ((np.array(X_mat[:,ts_inds[j]])-X_fitting[ts_inds[j]])**2)\n",
    "            dist[:,i] = weights[i]*np.sum(dist_ts,axis=1)\n",
    "    \n",
    "    # return the mean across a row\n",
    "    # will be length equal to number of rows\n",
    "    return np.mean(dist,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipe_opt = Pipeline([\n",
    "                    ('union_feature', union),\n",
    "                    ('mix_knn', KNNMixedTSConsts(neighbors=6,\n",
    "                                                 ts_inds = np.arange(4,16),\n",
    "                                                 weights = [1.0,\n",
    "                                                            50.20425478187665,\n",
    "                                                            0.05320161750432445,\n",
    "                                                            0.4751064830429864,\n",
    "                                                            0.05650927225287341]))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/calvinwhealton/Documents/GitHub/floods_housing_zipcode/pickled_models')\n",
    "mix_knn_opt = pickle.load(open('mix_knn_opt.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Results for Each Zip Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hou_typ = [-0.4, 0.0, 0.3, 0.8] # housing market typical values\n",
    "gdp_typ = [-0.6, 2., 5.] # gdp typical values\n",
    "flood = 100. # 100-year return period\n",
    "\n",
    "size=15\n",
    "params = {'legend.fontsize': 'large',\n",
    "          'figure.figsize': (20,8),\n",
    "          'axes.labelsize': size,\n",
    "          'axes.titlesize': size,\n",
    "          'xtick.labelsize': size*0.75,\n",
    "          'ytick.labelsize': size*0.75,\n",
    "          'axes.titlepad': 0,\n",
    "          'axes.titlepad': 25}\n",
    "\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "# loop over all zip codes (housing.shape[0])\n",
    "for z in housing['GEOID10_str'].values:\n",
    "    \n",
    "    # checking if there is population density and median income data for zip code\n",
    "    if z in zips_key_vals3['zips'].values:\n",
    "        med_inc = zips_key_vals3.loc[zips_key_vals3['zips'] == z, 'med_hh_inc']\n",
    "        pop_den = zips_key_vals3.loc[zips_key_vals3['zips'] == z, 'pop_dens']\n",
    "        \n",
    "        # dataframe that will be sent to the machine learning model\n",
    "        typ_dat = pd.DataFrame(columns = ['flood_rp','GDP','pop_dens','h-12',\n",
    "                                         'h-11','h-10','h-09','h-08','h-07','h-06',\n",
    "                                         'h-05','h-04','h-03','h-02','h-01'])\n",
    "        # loop to create a dataframe\n",
    "        for h in hou_typ:\n",
    "            for g in gdp_typ:\n",
    "                \n",
    "                # adding row to dataframe\n",
    "                typ_dat =  typ_dat.append({'flood_rp':flood,\n",
    "                                    'GDP': g,\n",
    "                                    'med_inc': med_inc,\n",
    "                                    'pop_dens': pop_den,\n",
    "                                    'h-12':h,\n",
    "                                    'h-11':h,\n",
    "                                    'h-10':h,\n",
    "                                    'h-09':h,\n",
    "                                    'h-08':h,\n",
    "                                    'h-07':h,\n",
    "                                    'h-06':h,\n",
    "                                    'h-05':h,\n",
    "                                    'h-04':h,\n",
    "                                    'h-03':h,\n",
    "                                    'h-02':h,\n",
    "                                    'h-01':h},ignore_index=True)\n",
    "                \n",
    "                \n",
    "        # making predictions from the machine learning model\n",
    "        # predictions will be an n x t x 3 array\n",
    "        # n = number of typical cases (3*4)\n",
    "        # t = number of time periods (13)\n",
    "        # mean, 90th percentile, 10th percentile\n",
    "        zip_preds = mix_knn_opt.predict(typ_dat)\n",
    "        \n",
    "        # changing directory to folder for images\n",
    "        os.chdir('/Users/calvinwhealton/Documents/GitHub/floods_housing_zipcode/visualizations/zip_results/zip_pred_100yr')\n",
    "        \n",
    "        gdp_poly_cols = ['#d7191c40', '#ffffbf40', '#2c7bb640']\n",
    "        gdp_line_cols = ['#d7191c', 'gold', '#2c7bb6']\n",
    "        \n",
    "        # open plot\n",
    "        plt. plot()\n",
    "        ind = 0\n",
    "        for ind2 in range(len(hou_typ)):\n",
    "            plt.plot()\n",
    "            # plot all the background polygons\n",
    "            for ind1 in range(len(gdp_typ)):\n",
    "                ind_take = ind\n",
    "                plt.plot(np.arange(-12,1), [typ_dat['h-12'].values[ind_take]]*13, color='black')\n",
    "                plt.fill_between(np.arange(0,13), zip_preds[ind_take,:,1], zip_preds[ind_take,:,2],color=gdp_poly_cols[ind1])\n",
    "                #print(ind)\n",
    "                ind += 1\n",
    "                \n",
    "            # plot mean predictions\n",
    "            ind -= len(gdp_typ)\n",
    "            for ind1 in range(len(gdp_typ)):\n",
    "                ind_take = ind\n",
    "                plt.plot(np.arange(0,13), zip_preds[ind_take,:,0], color=gdp_line_cols[ind1])\n",
    "                ind += 1\n",
    "\n",
    "            # add labels and titles\n",
    "            plt.ylabel('ZHVI Change (month-over-month)')\n",
    "            plt.xlabel('Month Relative to Flood')\n",
    "            plt.title(str(int(z)).zfill(5) + [' Poor', ' Neutral',' Typical', ' Good'][ind2] + ' Pre-Flood Housing Market ')\n",
    "            \n",
    "            # saving figure\n",
    "            fig_name = str(int(z)).zfill(5) + ['_Poor', '_Neutral','_Typical', '_Good'][ind2] + '_market.png'\n",
    "            plt.savefig(fig_name)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
