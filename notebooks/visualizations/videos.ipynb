{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures and Videos\n",
    "_Calvin Whealton_\n",
    "\n",
    "Figures created for 2020-07-15 update."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard libraries used for plotting/wrangling/etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening the US coastline file for the 48 contiguous states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/calvinwhealton/Documents/GitHub/floods_housing_zipcode/data/geo_data/US_48_COASTLINE')\n",
    "us_48_coast = gpd.read_file('US_COASTLINE.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = us_48_coast.plot(color='white',edgecolor='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trend in Flooding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the trend in flooding using the kendall tau value bewteen the flood series and the \"year\". THe scipy kendall tau value and the associated p-value are used to determine the strength of the trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kendalltau\n",
    "\n",
    "# calculating trends in each gage\n",
    "os.chdir('/Users/calvinwhealton/Documents/GitHub/floods_housing_zipcode/data/gage_data/peak_flows')\n",
    "\n",
    "# finding all files in the directory\n",
    "list_files = os.listdir()\n",
    "\n",
    "# initializing dataframe to store results\n",
    "kendallt_df = pd.DataFrame(columns=['gage','tau','pvalue'])\n",
    "\n",
    "# looping over files\n",
    "for f in list_files:\n",
    "    # read in file\n",
    "    temp = pd.read_csv(f)\n",
    "    \n",
    "    # checking that there are observations in the file\n",
    "    if len(temp) != 0:\n",
    "\n",
    "        # peak values\n",
    "        peaks = temp['peak_va'].values\n",
    "\n",
    "        # calculated kendal tau\n",
    "        kendall_tau_lag1 = kendalltau(peaks,range(0,len(peaks)))\n",
    "\n",
    "        # adding to dataframe\n",
    "        kendallt_df = kendallt_df.append({'gage':f.split('.')[0],'tau':kendall_tau_lag1.correlation,'pvalue':kendall_tau_lag1.pvalue},ignore_index=True)\n",
    "\n",
    "kendallt_df.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kendallt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in supplemental data that include the location of the gage\n",
    "os.chdir('/Users/calvinwhealton/Documents/GitHub/floods_housing_zipcode/data/gage_data')\n",
    "gage_supp = pd.read_csv('usgs_supp.txt',sep='\\t',skiprows=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gage_supp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kendallt_df['site_no'] = kendallt_df['gage'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_cols_gages(df):\n",
    "    '''\n",
    "    function to assign colors to gages\n",
    "    assign color based on the p-value and trend in the gage\n",
    "    emphasizes gages with significant and increasing trends\n",
    "    '''\n",
    "    \n",
    "    col_list = []\n",
    "    \n",
    "    for i in df.index:\n",
    "        if df.loc[i,'tau'] > 0 and df.loc[i,'pvalue'] <0.05:\n",
    "            col_list.append('#b2182b')\n",
    "        elif df.loc[i,'tau'] > 0 and df.loc[i,'pvalue'] < 0.10:\n",
    "            col_list.append('#ef8a62')\n",
    "        elif df.loc[i,'tau'] < 0 and df.loc[i,'pvalue'] <0.20:\n",
    "            col_list.append('#fddbc7')\n",
    "        else:\n",
    "            col_list.append('#f7f7f7')\n",
    "            \n",
    "    return col_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting gages to a geodataframe\n",
    "gage_supp_gdf = gpd.GeoDataFrame(\n",
    "    gage_supp, geometry=gpd.points_from_xy(gage_supp.dec_long_va, gage_supp.dec_lat_va))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed because there are two gages with the name number somewhere\n",
    "gage_supp_gdf2 = gage_supp_gdf[~gage_supp_gdf['site_no'].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging with the kendall tau dataframe, so kendall tau values can be plotted across the US\n",
    "gage_supp_gdf2 = gage_supp_gdf2.merge(kendallt_df,on='site_no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gage_supp_gdf2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a new column for the color for each point\n",
    "gage_supp_gdf2['pt_col'] = assign_cols_gages(gage_supp_gdf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (40,30)\n",
    "\n",
    "plt.rcParams[\"font.size\"] = \"50\"\n",
    "base = us_48_coast.plot(color='gainsboro',edgecolor='black')\n",
    "gage_supp_gdf2.plot(ax=base,color=gage_supp_gdf2['pt_col'].values,marker='o',markersize=60)\n",
    "plt.xlabel('Longitude',fontsize=50)\n",
    "plt.ylabel('Latitude',fontsize=50)\n",
    "plt.title('Stream Gages in Contiguous United States',fontsize=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Videos\n",
    "\n",
    "Making videos for the data. First step is to make a lot of plots, one for each time period and each type of data desired. Then the plots for a single year will be stitched together. Then, the plots will be stitched together in sequence to form a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# national flood insurance claims at the yearly time stamp\n",
    "os.chdir('/Users/calvinwhealton/Documents/GitHub/floods_housing_zipcode/data/processed_data')\n",
    "claims = pd.read_csv('ts_claims.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims['GEOID102'] = claims['zips'].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapefile that includes locations for each zip code (shapefile of zip code and interpolation latitude and longitude)\n",
    "os.chdir('/Users/calvinwhealton/Documents/GitHub/floods_housing_zipcode/data/geo_data/tl_2019_us_zcta510')\n",
    "zips_latlong = gpd.read_file('tl_2019_us_zcta510.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zips_latlong.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting string values to float, if needed\n",
    "zips_latlong['loc_x'] = zips_latlong['INTPTLON10'].values.astype(float)\n",
    "zips_latlong['loc_y'] = zips_latlong['INTPTLAT10'].values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zips_latlong_df = pd.DataFrame(zips_latlong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zips_latlong_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zips_latlong.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zips_latlong_df = zips_latlong_df.drop(columns=['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting values to a geopandas dataframe\n",
    "# use interpolation latitude and longitude for reference\n",
    "zips_latlong_gdf = gpd.GeoDataFrame(\n",
    "    zips_latlong_df, geometry=gpd.points_from_xy(zips_latlong_df.loc_x, zips_latlong_df.loc_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zips_latlong_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zips_latlong_gdf['GEOID102'] = zips_latlong_gdf['GEOID10'].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_gdf = zips_latlong_gdf.merge(claims,on='GEOID102')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cols_claims(lister):\n",
    "    '''\n",
    "    function to define colors for claims\n",
    "    assigns the color based on the amount of the claim\n",
    "    '''\n",
    "    col_list = []\n",
    "    for ind in range(len(lister)):\n",
    "        if abs(lister[ind]) > 0:\n",
    "            col_list.append('#6a51a3')\n",
    "        else:\n",
    "            col_list.append('#fcfbfd00')\n",
    "            \n",
    "    return col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making example plot about claims\n",
    "df_temp = gpd.GeoDataFrame(claims_gdf, columns =['2000', 'geometry']) \n",
    "base = us_48_coast.plot(color='gainsboro',edgecolor='black')\n",
    "df_temp.plot(ax=base,color= cols_claims(df_temp['2000'].values) ,marker='o',markersize=60)\n",
    "plt.xlabel('Longitude',fontsize=50)\n",
    "plt.ylabel('Latitude',fontsize=50)\n",
    "plt.title('Flood Claims',fontsize=100)\n",
    "plt.rcParams[\"font.size\"] = \"50\"\n",
    "plt.rcParams[\"figure.figsize\"] = (40,30)\n",
    "plt.xlim((-130,-65))\n",
    "plt.ylim((24,50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cols_rps(lister):\n",
    "    '''\n",
    "    function to assign colors based on return periods\n",
    "    redder colors assign as more extreme events\n",
    "    '''\n",
    "    col_list = []\n",
    "    for ind in range(len(lister)):\n",
    "        if abs(lister[ind]) > 500:\n",
    "            col_list.append('#a50f15')\n",
    "        elif abs(lister[ind] > 100):\n",
    "            col_list.append('#fb6a4a')\n",
    "        elif abs(lister[ind] > 25):\n",
    "            col_list.append('#fee5d9')\n",
    "        else:\n",
    "            col_list.append('#fcfbfd00')\n",
    "    return col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading in return period data\n",
    "os.chdir('/Users/calvinwhealton/Documents/GitHub/floods_housing_zipcode/data/processed_data')\n",
    "rps_ts = pd.read_csv('ts_rps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rps_ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rps_ts['Gage'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rps_ts['site_no'] = rps_ts['Gage'].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gage_supp_gdf3 = gage_supp_gdf2.merge(rps_ts,on='site_no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making an example plot for the return periods\n",
    "df_temp = gpd.GeoDataFrame(gage_supp_gdf3, columns =['2017', 'geometry']) \n",
    "base = us_48_coast.plot(color='gainsboro',edgecolor='black')\n",
    "df_temp.plot(ax=base,color= cols_rps(df_temp['2017'].values) ,marker='o',markersize=200)\n",
    "plt.xlabel('Longitude',fontsize=50)\n",
    "plt.ylabel('Latitude',fontsize=50)\n",
    "plt.title('Flood Claims',fontsize=100)\n",
    "plt.rcParams[\"font.size\"] = \"50\"\n",
    "plt.rcParams[\"figure.figsize\"] = (40,30)\n",
    "plt.xlim((-130,-65))\n",
    "plt.ylim((24,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directory where all plots will be saved\n",
    "os.chdir('/Users/calvinwhealton/Documents/GitHub/floods_housing_zipcode/visualizations/videos/figs_2020-07-22')\n",
    "\n",
    "# loop to create the plots\n",
    "for i in range(1996,2019):\n",
    "    plt.rcParams[\"font.size\"] = \"50\"\n",
    "    plt.rcParams[\"figure.figsize\"] = (40,15)\n",
    "\n",
    "    df_temp = gpd.GeoDataFrame(claims_gdf, columns =[str(i), 'geometry']) \n",
    "    base = us_48_coast.plot(color='gainsboro',edgecolor='black')\n",
    "    df_temp.plot(ax=base,color= cols_claims(df_temp[str(i)].values) ,marker='o',markersize=60)\n",
    "    plt.xlabel('Longitude',fontsize=50)\n",
    "    plt.ylabel('Latitude',fontsize=50)\n",
    "    plt.title('Flood Insurance Claims ' + str(i),fontsize=100)\n",
    "    plt.rcParams[\"font.size\"] = \"50\"\n",
    "    plt.rcParams[\"figure.figsize\"] = (40,30)\n",
    "    plt.xlim((-130,-65))\n",
    "    plt.ylim((24,50))\n",
    "    \n",
    "    plt.savefig(fname=('claims_'+str(i)+'.png'),Bbox='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directory where all plots will be saved\n",
    "os.chdir('/Users/calvinwhealton/Documents/GitHub/floods_housing_zipcode/visualizations/videos/figs_2020-07-22')\n",
    "\n",
    "# loop to create the plots\n",
    "for i in range(1996,2019):\n",
    "    \n",
    "    plt.rcParams[\"font.size\"] = \"50\"\n",
    "    plt.rcParams[\"figure.figsize\"] = (40,15)\n",
    "    \n",
    "    df_temp = gpd.GeoDataFrame(gage_supp_gdf3, columns =[str(i), 'geometry']) \n",
    "    base = us_48_coast.plot(color='gainsboro',edgecolor='black')\n",
    "    df_temp.plot(ax=base,color= cols_rps(df_temp[str(i)].values) ,marker='o',markersize=200)\n",
    "    plt.xlabel('Longitude',fontsize=50)\n",
    "    plt.ylabel('Latitude',fontsize=50)\n",
    "    plt.title('Gage Return Periods ' + str(i),fontsize=100)\n",
    "    plt.rcParams[\"font.size\"] = \"50\"\n",
    "    plt.rcParams[\"figure.figsize\"] = (40,30)\n",
    "    plt.xlim((-130,-65))\n",
    "    plt.ylim((24,50))\n",
    "    \n",
    "    plt.savefig(fname=('gages_'+str(i)+'.png'),Bbox='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stiching the figures together\n",
    "# taken from: https://note.nkmk.me/en/python-pillow-concat-images/\n",
    "from PIL import Image\n",
    "\n",
    "def get_concat_h(im1, im2):\n",
    "    dst = Image.new('RGB', (im1.width + im2.width, im1.height))\n",
    "    dst.paste(im1, (0, 0))\n",
    "    dst.paste(im2, (im1.width, 0))\n",
    "    return dst\n",
    "\n",
    "def get_concat_v(im1, im2):\n",
    "    dst = Image.new('RGB', (im1.width, im1.height + im2.height))\n",
    "    dst.paste(im1, (0, 0))\n",
    "    dst.paste(im2, (0, im1.height))\n",
    "    return dst\n",
    "\n",
    "for i in range(1996,2019):\n",
    "    im1 = Image.open('gages_'+str(i)+'.png')\n",
    "    im2 = Image.open('claims_'+str(i)+'.png')\n",
    "    \n",
    "    get_concat_v(im1, im2).save('combined/claim_gage_'+str(i)+'.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.video.io.ImageSequenceClip\n",
    "image_folder='/Users/calvinwhealton/Documents/GitHub/floods_housing_zipcode/visualizations/videos/figs_2020-07-22/combined'\n",
    "fps=1\n",
    "\n",
    "# need to sort the files because otherwise the years get jumbled\n",
    "image_files = sorted([image_folder+'/'+img for img in os.listdir(image_folder) if img.endswith(\".png\")])\n",
    "clip = moviepy.video.io.ImageSequenceClip.ImageSequenceClip(image_files, fps=fps)\n",
    "clip.write_videofile('claim_gage_video.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
